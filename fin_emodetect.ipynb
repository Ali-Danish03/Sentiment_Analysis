{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fa5ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b984dcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "      <td>Sage Act upgrade list tommorow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "      <td>WAY HOMEGIRL BABY FUNERAL MAN HATE FUNERALS SH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "      <td>eye  true hazel eyeand brilliant  Regular feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "      <td>ugh babe hugggzzz u  babe naamazed nga ako e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Emotion                                               Text  \\\n",
       "0           0  neutral                                             Why ?    \n",
       "1           1      joy    Sage Act upgrade on my to do list for tommorow.   \n",
       "2           2  sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...   \n",
       "3           3      joy   Such an eye ! The true hazel eye-and so brill...   \n",
       "4           4      joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...   \n",
       "\n",
       "                                          Clean_Text  \n",
       "0                                                NaN  \n",
       "1                     Sage Act upgrade list tommorow  \n",
       "2  WAY HOMEGIRL BABY FUNERAL MAN HATE FUNERALS SH...  \n",
       "3  eye  true hazel eyeand brilliant  Regular feat...  \n",
       "4    ugh babe hugggzzz u  babe naamazed nga ako e...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('emotion_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ead7ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9151dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = df[\"Emotion\"].unique()\n",
    "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "df[\"label_id\"] = df[\"Emotion\"].map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f147c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>label_id</th>\n",
       "      <th>Final_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Why ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "      <td>Sage Act upgrade list tommorow</td>\n",
       "      <td>1</td>\n",
       "      <td>Sage Act upgrade list tommorow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "      <td>WAY HOMEGIRL BABY FUNERAL MAN HATE FUNERALS SH...</td>\n",
       "      <td>2</td>\n",
       "      <td>WAY HOMEGIRL BABY FUNERAL MAN HATE FUNERALS SH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "      <td>eye  true hazel eyeand brilliant  Regular feat...</td>\n",
       "      <td>1</td>\n",
       "      <td>eye  true hazel eyeand brilliant  Regular feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "      <td>ugh babe hugggzzz u  babe naamazed nga ako e...</td>\n",
       "      <td>1</td>\n",
       "      <td>ugh babe hugggzzz u  babe naamazed nga ako e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34787</th>\n",
       "      <td>34787</td>\n",
       "      <td>surprise</td>\n",
       "      <td>@MichelGW have you gift! Hope you like it! It'...</td>\n",
       "      <td>gift Hope like it hand wear  Itll warm Lol</td>\n",
       "      <td>4</td>\n",
       "      <td>gift Hope like it hand wear  Itll warm Lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34788</th>\n",
       "      <td>34788</td>\n",
       "      <td>joy</td>\n",
       "      <td>The world didnt give it to me..so the world MO...</td>\n",
       "      <td>world didnt meso world DEFINITELY cnt away</td>\n",
       "      <td>1</td>\n",
       "      <td>world didnt meso world DEFINITELY cnt away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>34789</td>\n",
       "      <td>anger</td>\n",
       "      <td>A man robbed me today .</td>\n",
       "      <td>man robbed today</td>\n",
       "      <td>5</td>\n",
       "      <td>man robbed today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34790</th>\n",
       "      <td>34790</td>\n",
       "      <td>fear</td>\n",
       "      <td>Youu call it JEALOUSY, I call it of #Losing YO...</td>\n",
       "      <td>Youu JEALOUSY #Losing YOU</td>\n",
       "      <td>3</td>\n",
       "      <td>Youu JEALOUSY #Losing YOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34791</th>\n",
       "      <td>34791</td>\n",
       "      <td>sadness</td>\n",
       "      <td>I think about you baby, and I dream about you ...</td>\n",
       "      <td>think baby dream time</td>\n",
       "      <td>2</td>\n",
       "      <td>think baby dream time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34792 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   Emotion  \\\n",
       "0               0   neutral   \n",
       "1               1       joy   \n",
       "2               2   sadness   \n",
       "3               3       joy   \n",
       "4               4       joy   \n",
       "...           ...       ...   \n",
       "34787       34787  surprise   \n",
       "34788       34788       joy   \n",
       "34789       34789     anger   \n",
       "34790       34790      fear   \n",
       "34791       34791   sadness   \n",
       "\n",
       "                                                    Text  \\\n",
       "0                                                 Why ?    \n",
       "1        Sage Act upgrade on my to do list for tommorow.   \n",
       "2      ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...   \n",
       "3       Such an eye ! The true hazel eye-and so brill...   \n",
       "4      @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...   \n",
       "...                                                  ...   \n",
       "34787  @MichelGW have you gift! Hope you like it! It'...   \n",
       "34788  The world didnt give it to me..so the world MO...   \n",
       "34789                           A man robbed me today .    \n",
       "34790  Youu call it JEALOUSY, I call it of #Losing YO...   \n",
       "34791  I think about you baby, and I dream about you ...   \n",
       "\n",
       "                                              Clean_Text  label_id  \\\n",
       "0                                                    NaN         0   \n",
       "1                         Sage Act upgrade list tommorow         1   \n",
       "2      WAY HOMEGIRL BABY FUNERAL MAN HATE FUNERALS SH...         2   \n",
       "3      eye  true hazel eyeand brilliant  Regular feat...         1   \n",
       "4        ugh babe hugggzzz u  babe naamazed nga ako e...         1   \n",
       "...                                                  ...       ...   \n",
       "34787         gift Hope like it hand wear  Itll warm Lol         4   \n",
       "34788         world didnt meso world DEFINITELY cnt away         1   \n",
       "34789                                  man robbed today          5   \n",
       "34790                          Youu JEALOUSY #Losing YOU         3   \n",
       "34791                              think baby dream time         2   \n",
       "\n",
       "                                              Final_Text  \n",
       "0                                                 Why ?   \n",
       "1                         Sage Act upgrade list tommorow  \n",
       "2      WAY HOMEGIRL BABY FUNERAL MAN HATE FUNERALS SH...  \n",
       "3      eye  true hazel eyeand brilliant  Regular feat...  \n",
       "4        ugh babe hugggzzz u  babe naamazed nga ako e...  \n",
       "...                                                  ...  \n",
       "34787         gift Hope like it hand wear  Itll warm Lol  \n",
       "34788         world didnt meso world DEFINITELY cnt away  \n",
       "34789                                  man robbed today   \n",
       "34790                          Youu JEALOUSY #Losing YOU  \n",
       "34791                              think baby dream time  \n",
       "\n",
       "[34792 rows x 6 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Final_Text\"] = df[\"Clean_Text\"].fillna(df[\"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "478bf9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion\n",
      "joy         11045\n",
      "sadness      6722\n",
      "fear         5410\n",
      "anger        4297\n",
      "surprise     4062\n",
      "neutral      2254\n",
      "disgust       856\n",
      "shame         146\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Emotion\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa7f9a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"Final_Text\"], df[\"label_id\"],\n",
    "    test_size=0.3, random_state=42, stratify=df[\"label_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4edc568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encodings = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encodings[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encodings[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "train_dataset = EmotionDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = EmotionDataset(val_texts, val_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9736d92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9dce877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5880082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adnis\\AppData\\Local\\Temp\\ipykernel_5300\\2010974743.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_results\",\n",
    "    do_eval=True,                # instead of evaluation_strategy\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./bert_logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=1\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5de98c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./emotion_model\\\\tokenizer_config.json',\n",
       " './emotion_model\\\\special_tokens_map.json',\n",
       " './emotion_model\\\\vocab.txt',\n",
       " './emotion_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./emotion_model\")\n",
    "tokenizer.save_pretrained(\"./emotion_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2682841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I am  sad today!', 'predicted_label': 'fear', 'confidence': 0.19364005327224731, 'all_probs': {'neutral': 0.13711442053318024, 'joy': 0.1423381119966507, 'sadness': 0.09443894028663635, 'fear': 0.19364005327224731, 'surprise': 0.09870859235525131, 'anger': 0.05217939615249634, 'shame': 0.14698702096939087, 'disgust': 0.13459345698356628}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    probs = probs.detach().cpu().numpy()[0]\n",
    "    pred_id = np.argmax(probs)\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"predicted_label\": id2label[pred_id],\n",
    "        \"confidence\": float(probs[pred_id]),\n",
    "        \"all_probs\": {id2label[i]: float(p) for i, p in enumerate(probs)}\n",
    "    }\n",
    "\n",
    "\n",
    "print(predict(\"I am  sad today!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9cb5f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'I am  sad today!', 'predicted_label': 'fear', 'confidence': 0.19364005327224731, 'all_probs': {'neutral': 0.13711442053318024, 'joy': 0.1423381119966507, 'sadness': 0.09443894028663635, 'fear': 0.19364005327224731, 'surprise': 0.09870859235525131, 'anger': 0.05217939615249634, 'shame': 0.14698702096939087, 'disgust': 0.13459345698356628}}\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"I am  sad today!\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
